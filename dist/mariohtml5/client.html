<!DOCTYPE html>
<html>
	<head>
		<title>Infinite Mario - JavaScript</title>
        <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.4.2/jquery.min.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<style>
video {
  /* override other styles to make responsive */
  width: 100%    !important;
  height: auto   !important;
  max-width: 700px;
}
</style>

	</head>
	<body>
		<canvas id="canvas" style="display: none">
			<p>Your browser does not support the canvas element.</p>
		</canvas>
		<video id="view">
			<p>Your browser does not support the video element.</p>
        </video>
    <style>
      #outgoing {
        width: 600px;
        word-wrap: break-word;
        white-space: normal;
      }
    </style>
    <form id="signalform">
      <label for="incoming">Enter host id:</label>
      <input id="incoming" name="incoming">
      <button type="submit">Submit</button>
    </form>
    <script src="https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js"></script>
    <script>

const hadamar = (a, b) => Array.from(a).reduce((v, _, i) => v + (a[i] === b[i] ? 1 : 0), 0);
const argFact = (compareFn) => (array) => array.map((el, idx) => [el, idx]).reduce(compareFn)[1]
const argMax = argFact((min, el) => (el[0] > min[0] ? el : min))

var grammar = '#JSGF V1.0; grammar colors; public <color> = aqua | azure | beige | bisque | black | blue | brown | chocolate | coral | crimson | cyan | fuchsia | ghostwhite | gold | goldenrod | gray | green | indigo | ivory | khaki | lavender | lime | linen | magenta | maroon | moccasin | navy | olive | orange | orchid | peru | pink | plum | purple | red | salmon | sienna | silver | snow | tan | teal | thistle | tomato | turquoise | violet | white | yellow ;'
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const SpeechGrammarList = window.SpeechGrammarList || window.webkitSpeechGrammarList;
var recognition = new SpeechRecognition();
var speechRecognitionList = new SpeechGrammarList();
speechRecognitionList.addFromString(grammar, 1);
recognition.grammars = speechRecognitionList;
recognition.continuous = false;
recognition.lang = 'en-US';
recognition.interimResults = true;
recognition.maxAlternatives = 1;


recognition.onresult = function(event) {
        console.log(event);
        const transcripts = event.results[0][0].transcript.split(' ');
        transcripts.map(ts => {
        const transcript = ts.toLowerCase();

        console.log(transcript);
        const keys = {'left': 37, 'right': 39, 'jump': 83};
        //const colors = Object.keys(keys);

        //const h = colors.map(c => hadamar(transcript, c))
        //if (h.every(x => x === 0)) return;
        //const keyCode = keys[colors[argMax(h)]];
        const keyCode = keys[transcript];
        if (!keyCode) return;

        document.dispatchEvent(new KeyboardEvent('keydown', {keyCode}));
        setTimeout(() => document.dispatchEvent(new KeyboardEvent('keyup', {keyCode})), 300);
        });
}

recognition.onend = () => recognition.start();

recognition.start()
console.log('Ready to receive a color command.');

      const view = document
          .querySelector('#view');

      view.width = view.parentElement.offsetWidth; 
      view.height = view.width * 480 / 640; 

      const handleCon = conn => {
        conn.on('open', () => {
            document
                .addEventListener('keydown', ev => {
                    ev.preventDefault()
                    console.log(ev);
                    conn.send({type: ev.type, keyCode: ev.keyCode})
                })
            document
                .addEventListener('keyup', ev => {
                    ev.preventDefault()
                    console.log(ev);
                    conn.send({type: ev.type, keyCode: ev.keyCode})
                })
        });
      };


      const p = new Peer();
      p.on('error', err => console.log('error', err))

      document.querySelector('#signalform').addEventListener('submit', ev => {
        ev.preventDefault()

        const id = document.querySelector('#incoming').value;
        const con = p.connect(id);
        handleCon(con);

        const mediaStream = document.querySelector('#canvas').captureStream(25);
        const call = p.call(id, mediaStream); 
        console.log(call);

        call.on('stream', stream => {
          console.log("received stream", stream);
          view.srcObject = stream;
          view.onloadedmetadata = e => {
            view.play();
          };
        });
      })

    </script>


	</body>
</html>
